# Pre-Production Testing Checklist

## ‚ö†Ô∏è Current Status: ALMOST READY - Minor Issues to Fix

### ‚úÖ What's Working

**Core System**:
- ‚úÖ File watcher (auto-reload bug fixed)
- ‚úÖ Python imports (all core modules load)
- ‚úÖ Gate engine (4 gates implemented)
- ‚úÖ Audit logging (JSONL format)
- ‚úÖ API endpoints (FastAPI + WebSocket)
- ‚úÖ Frontend dashboard (3 views)
- ‚úÖ Digital signatures (SHA-256 hashing)

**Production Readiness**:
- ‚úÖ Desktop launchers (Windows/Mac/Linux)
- ‚úÖ CLI commands (monitor, check, audit, verify, init, doctor)
- ‚úÖ Documentation (INSTALL.md, QUICKSTART.md, USER_FLOWS.md)
- ‚úÖ Error handling (try/catch, graceful degradation)
- ‚úÖ Event-driven architecture (MECE timestamp filtering)

---

## ‚ö†Ô∏è Issues to Fix Before Real Data

### 1. TypeScript Compilation
**Issue**: Stub function left in App.tsx (line 273)
**Status**: ‚úÖ FIXED
**Test**: `npm run build` should succeed

### 2. Test Digital Signature Modal
**Issue**: Just implemented, never tested with real user interaction
**Required Test**:
```
1. Start monitor: python cli.py monitor --dashboard
2. Open http://localhost:5173
3. Click "Bypass HALT" button
4. Verify modal appears with:
   - Justification textarea
   - Signature input
   - Non-repudiation warning
   - Submit button (disabled until filled)
5. Fill both fields
6. Click "Submit Override"
7. Verify hash shown in confirmation
8. Check audit log: python cli.py audit --filter override
9. Verify signature: python cli.py verify
```

### 3. Large Excel File Handling
**Issue**: Only tested with small demo file (2 assertions)
**Required Test**:
```
- Create Excel with 50+ assertions
- Test file read performance
- Check memory usage
- Verify all assertions processed
```

### 4. High-Frequency Changes
**Issue**: File watcher debounce set to 0.9s, not tested with rapid saves
**Required Test**:
```
- Rapidly edit Excel (save every 2 seconds for 30 seconds)
- Verify no race conditions
- Check governance cycles don't overlap
- Monitor memory for leaks
```

### 5. Edge Cases
**Issue**: Not tested with:
- Missing Excel file
- Corrupted Excel file
- Invalid cell references
- Empty PERT distributions
- Negative numbers in distributions

---

## üß™ Testing Plan for Real Data

### Phase 1: Single Assertion (Low Risk)
**Goal**: Validate basic functionality

```bash
# 1. Create test manifest
cd guardian
python cli.py init real-data-test
cd real-data-test

# 2. Edit manifest for ONE assertion
# Point to real Excel file
# Use safe PERT ranges

# 3. Validate
python ../guardian/cli.py validate project_space/manifest.json

# 4. One-time check
python ../guardian/cli.py check \
  project_space/manifest.json \
  project_space/your_file.xlsx

# 5. If PASS, start monitoring
python ../guardian/cli.py monitor --dashboard
```

**Success Criteria**:
- ‚úÖ Manifest validates
- ‚úÖ Check completes without errors
- ‚úÖ Dashboard shows assertion
- ‚úÖ Modifying Excel triggers governance cycle
- ‚úÖ HALT triggers when data drifts
- ‚úÖ Audit log written

### Phase 2: Multiple Assertions (Medium Risk)
**Goal**: Test scalability

```bash
# Add 5-10 assertions to manifest
# Each monitoring different cells
# Mix of PASS and HALT states

# Start monitoring
python cli.py monitor --dashboard

# Test:
- Edit one cell at a time
- Edit multiple cells
- Save rapidly
- Check dashboard updates
- Verify audit log accuracy
```

**Success Criteria**:
- ‚úÖ All assertions visible in dashboard
- ‚úÖ Individual gate status shown correctly
- ‚úÖ No performance degradation
- ‚úÖ Governance Velocity chart populated
- ‚úÖ Data Health Status accurate

### Phase 3: Real Production Data (Full Risk)
**Goal**: Production deployment

```bash
# Use actual financial model
# Add all critical assertions
# Configure PERT ranges from historical data

# Run for 1 week in parallel with existing process
# Compare results
# Gather team feedback
```

**Success Criteria**:
- ‚úÖ Zero crashes/errors
- ‚úÖ All HALTs legitimate
- ‚úÖ No false positives
- ‚úÖ Team finds it useful
- ‚úÖ Audit trail complete

---

## üîç Pre-Flight Checklist

Run these commands to verify system health:

```bash
# 1. System diagnostics
cd guardian
python cli.py doctor

# Expected: All ‚úì PASS

# 2. Python imports
python -c "from core.loader import ManifestLoader; from core.brain import GateEngine; print('‚úì OK')"

# Expected: ‚úì OK

# 3. Frontend build
cd ../dashboard
npm run build

# Expected: Build succeeds, no TypeScript errors

# 4. Start monitor
cd ../guardian
python cli.py monitor --dashboard

# Expected: 
# - Terminal shows TUI
# - No Python errors
# - Dashboard at http://localhost:5173

# 5. Test demo project
# Edit project_space/test_model.xlsx
# Save file
# Observe governance cycle triggers

# Expected:
# - TUI updates
# - Dashboard refreshes
# - Audit log entry created

# 6. Test bypass modal
# Click "Bypass HALT" in dashboard
# Fill justification and signature
# Submit

# Expected:
# - Hash displayed in confirmation
# - Audit log entry with signature_hash

# 7. Verify signatures
python cli.py verify

# Expected: ‚úì All signatures verified

# 8. Check audit log
python cli.py audit --limit 20

# Expected: Recent events shown

# 9. Stop monitor (Ctrl+C)
# Expected: Clean shutdown, no errors
```

---

## ‚ö†Ô∏è Known Limitations

### 1. Concurrent Users
**Issue**: Not tested with multiple users editing same Excel file
**Mitigation**: Single-user workflows only for now
**Future**: Add file locking or multi-user coordination

### 2. Excel Formula Complexity
**Issue**: Only basic formula hash detection
**Mitigation**: May not catch all formula changes
**Future**: Enhanced formula parsing

### 3. Network Reliability
**Issue**: WebSocket can disconnect
**Mitigation**: Polling fallback exists
**Future**: Add reconnection logic with exponential backoff

### 4. Audit Log Size
**Issue**: JSONL file grows unbounded
**Mitigation**: `archive` command available
**Future**: Automatic rotation

### 5. Override Bypass
**Issue**: Bypass doesn't actually stop HALTs, just logs them
**Mitigation**: Documented behavior
**Future**: Implement actual bypass mechanism in gate engine

---

## üöÄ Recommended Rollout Strategy

### Week 1: Internal Testing
- Developer team tests with synthetic data
- Fix any bugs found
- Gather UX feedback
- Refine PERT ranges

### Week 2: Pilot Team (3-5 users)
- Select non-critical Excel models
- Train users on HALT response
- Monitor audit logs daily
- Iterate on documentation

### Week 3: Expanded Pilot (10-15 users)
- Add medium-criticality models
- Test CI/CD integration
- Validate signature verification
- Performance testing

### Week 4: Production Rollout
- All users
- All critical models
- Full monitoring
- Weekly audit reviews

---

## üõ°Ô∏è Safety Measures

### Read-Only Mode
The guardian monitors but **does NOT modify** Excel files:
- ‚úÖ Safe to run alongside existing workflows
- ‚úÖ Can be disabled anytime (Ctrl+C)
- ‚úÖ Audit log is only output

### Backup Requirement
Before real data:
```bash
# Backup Excel files
cp project_space/*.xlsx project_space/backups/

# Backup manifest
cp project_space/manifest.json project_space/manifest.backup.json
```

### Kill Switch
If issues occur:
```bash
# Stop monitor
Ctrl+C

# Check what's running
python cli.py doctor

# Review logs
python cli.py audit --limit 50
```

---

## ‚úÖ Final Pre-Production Test

Run this complete workflow:

```bash
# 1. Fresh start
cd guardian
python cli.py init production-test
cd production-test

# 2. Configure manifest with real data
# Edit project_space/manifest.json
# Point to actual Excel file
# Set conservative PERT ranges

# 3. Validate
python ../guardian/cli.py validate project_space/manifest.json

# 4. Dry run
python ../guardian/cli.py check \
  project_space/manifest.json \
  project_space/your_file.xlsx

# 5. Review results
# - If HALT, understand why
# - Adjust PERT ranges if needed
# - Re-validate

# 6. Start live monitoring
python ../guardian/cli.py monitor --dashboard

# 7. Edit Excel file
# Make a change that SHOULD trigger HALT

# 8. Verify detection
# - TUI shows HALT
# - Dashboard shows HALT details
# - Audit log entry created

# 9. Test bypass
# - Click "Bypass HALT"
# - Enter justification and signature
# - Submit
# - Verify hash stored

# 10. Verify signatures
python ../guardian/cli.py verify

# If all steps pass: READY FOR PRODUCTION ‚úÖ
```

---

## üìä Success Metrics

After 1 week of production use, measure:

- **Zero Downtime**: Monitor runs continuously
- **Audit Coverage**: All critical assertions monitored
- **HALT Accuracy**: <5% false positives
- **Response Time**: Team responds to HALTs within 1 hour
- **Signature Integrity**: 100% of overrides verified valid
- **User Satisfaction**: >80% find it useful

---

## üéØ My Recommendation

**Status**: **READY with minor testing required**

**Action Plan**:
1. ‚úÖ Fix TypeScript error (DONE)
2. ‚ö†Ô∏è Test bypass modal with real interaction (5 min)
3. ‚ö†Ô∏è Run one complete test cycle (10 min)
4. ‚ö†Ô∏è Test with larger Excel file (15 min)
5. ‚úÖ Deploy to pilot team (1 hour)

**Timeline**: Could go to production in **30 minutes** after final testing

**Risk Level**: **LOW**
- System is read-only (doesn't modify Excel)
- Can be killed anytime
- Has been running stable for hours
- All core features tested individually

**Confidence**: **85%** - Would be 95% after bypass modal test

**Blocker**: Test the bypass modal signature flow end-to-end before real data.
